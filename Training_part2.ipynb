{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "capstone_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52hLiv5iiqg-",
        "outputId": "e166bd9d-a1d0-4c27-897f-5292cdb1b081"
      },
      "source": [
        "!git clone https://github.com/vigneshbabupj/Project_Vision.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Project_Vision'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 1931 (delta 30), reused 39 (delta 15), pack-reused 1877\u001b[K\n",
            "Receiving objects: 100% (1931/1931), 1.24 MiB | 28.93 MiB/s, done.\n",
            "Resolving deltas: 100% (1297/1297), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDtEGSF0cUcA",
        "outputId": "cd083e3a-d743-475d-b43b-fea0c046f166"
      },
      "source": [
        "!pip install git+https://github.com/longcw/RoIAlign.pytorch -q"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for roi-align (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs-oKjjAswXr",
        "outputId": "17e8a84e-6ff3-44a9-adde-cf352b38bbba"
      },
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mProject_Vision\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKgnX1ei62J2",
        "outputId": "589ebd64-fe46-44af-fc3e-0da504167091"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fifzpdDxtHJ9"
      },
      "source": [
        "%%capture\n",
        "%cd Project_Vision/\n",
        "!mkdir midas\n",
        "%cd midas\n",
        "!wget https://github.com/intel-isl/MiDaS/releases/download/v2_1/model-f6b98070.pt\n",
        "%cd .."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4d4vMwk7Dev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd1a3722-bf69-44dc-b7af-f99a938b8f8b"
      },
      "source": [
        "!cp '/content/gdrive/My Drive/EVA/EVA5/15A/planercnn_model/checkpoint.zip' '.'\n",
        "!unzip checkpoint.zip\n",
        "!ls \n",
        "!rm -r checkpoint.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  checkpoint.zip\n",
            "   creating: planercnn_normal_warping_refine/\n",
            "  inflating: planercnn_normal_warping_refine/checkpoint_refine.pth  \n",
            "  inflating: planercnn_normal_warping_refine/checkpoint.pth  \n",
            "anchors\t\tdetect.py   model.py\t\t\t     pytorch_ssim\n",
            "bbox_decoder\tdocuments   options.py\t\t\t     README.md\n",
            "checkpoint.zip\tencoder.py  plane_decoder\t\t     train.py\n",
            "dataset.py\tLICENSE     planercnn_normal_warping_refine\n",
            "depth_decoder\tmidas\t    pytorch_msssim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g30rpbOH7VjF"
      },
      "source": [
        "%%capture\n",
        "%cd Project_Vision/\n",
        "!cp '/content/gdrive/My Drive/EVA/updated_final_data.zip' '.'\n",
        "\n",
        "!unzip updated_final_data.zip\n",
        "!rm -r updated_final_data.zip"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTGtTYkaEcac",
        "outputId": "ce4c6b84-31af-4ac9-83f9-a011e643a011"
      },
      "source": [
        "ls data/customdata/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "custom.data   \u001b[0m\u001b[01;34mdepth_images\u001b[0m/  \u001b[01;34mlabels\u001b[0m/                    test.txt\n",
            "custom.names  \u001b[01;34mimages\u001b[0m/        planercnn_data_actual.zip  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6ZnLtJk7rqW"
      },
      "source": [
        "%%capture\n",
        "%cd data/customdata/\n",
        "!unzip planercnn_data_actual.zip\n",
        "!rm -r planercnn_data_actual.zip"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtHRw_rg8yXF",
        "outputId": "59e961b1-8723-4a56-bbaa-e564e66af3ec"
      },
      "source": [
        "ls "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcontent\u001b[0m/     custom.names   \u001b[01;34mimages\u001b[0m/  test.txt\n",
            "custom.data  \u001b[01;34mdepth_images\u001b[0m/  \u001b[01;34mlabels\u001b[0m/  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvesCKoh8RLd",
        "outputId": "51415d70-cc6b-40c7-d0b0-1a3752e765cb"
      },
      "source": [
        "!mv -v 'content/planercnn/test/inference' '.'\n",
        "!cp '/content/gdrive/My Drive/EVA/EVA5/15A/custom.shapes' '.'\n",
        "!cp '/content/gdrive/My Drive/EVA/EVA5/15A/camera.txt' './images'\n",
        "%cd ../../\n",
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "renamed 'content/planercnn/test/inference' -> './inference'\n",
            "/content/Project_Vision\n",
            "anchors        detect.py   model.py\t\t\t    pytorch_ssim\n",
            "bbox_decoder   documents   options.py\t\t\t    README.md\n",
            "data\t       encoder.py  plane_decoder\t\t    train.py\n",
            "dataset.py     LICENSE\t   planercnn_normal_warping_refine\n",
            "depth_decoder  midas\t   pytorch_msssim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHTwOemdoPuL"
      },
      "source": [
        "#Run Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w40T1g6jRZg5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba68719-1062-4dc1-b01c-29e7c87a045c"
      },
      "source": [
        "%cd Project_Vision/\n",
        "!sed -i '/-With-A-Puffy-Jacket-Boots-And-A-Belt.jpg/d' data/customdata/train.txt\n",
        "#!sed -i '1,10!d' data/customdata/train.txt \n",
        "#!sed -i '1,10!d' data/customdata/test.txt\n",
        "!git pull -f"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Project_Vision\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (5/5), done.\n",
            "From https://github.com/vigneshbabupj/Project_Vision\n",
            "   df71137..7d422c7  main       -> origin/main\n",
            "Updating df71137..7d422c7\n",
            "Fast-forward\n",
            " bbox_decoder/Actual_layers_sizes | 116 \u001b[32m+++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " dataset.py                       |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 2 files changed, 118 insertions(+), 2 deletions(-)\n",
            " create mode 100644 bbox_decoder/Actual_layers_sizes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iomh4thFkxyg"
      },
      "source": [
        "from options import *\n",
        "import sys\n",
        "sys.argv = ['']\n",
        "plane_args = plane_parse_args()\n",
        "yolo_args = yolo_parse_args()\n",
        "midas_args = midas_parse_args()\n",
        "\n",
        "yolo_args.batch_size = 1\n",
        "\n",
        "yolo_args.cfg = 'bbox_decoder/cfg/yolov3-custom.cfg'\n",
        "yolo_args.epochs = 10\n",
        "yolo_args.weights = '/content/gdrive/My Drive/EVA/EVA5/yolov3-spp-ultralytics.pt'\n",
        "yolo_args.data = 'data/customdata/custom.data'\n",
        "midas_args.input = 'data/customdata/images'\n",
        "#midas_args.output\n",
        "midas_args.weights = 'midas/model-f6b98070.pt'\n",
        "\n",
        "plane_args.customDataFolder = 'data/customdata/images'\n",
        "plane_args.checkpoint_dir = 'planercnn_normal_warping_refine'\n",
        "plane_args.suffix = 'warping_refine'\n",
        "\n",
        "yolo_args.img_size=[512,512,512] #[640,640,640]\n",
        "#yolo_args.img_size=[256,256,256] #[640,640,640]\n",
        "plane_args.height = 512\n",
        "plane_args.width = 512\n",
        "plane_args.test_dir = 'test'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lc8zdtDP4VL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "5c623faa-3b83-4482-dbe0-da4b868fa921"
      },
      "source": [
        "%matplotlib inline\n",
        "from train import train\n",
        "loss = train(plane_args,yolo_args,midas_args,add_plane_loss=1,add_yolo_loss=1,add_midas_loss=1,resume_train=True,model_path='/content/gdrive/My Drive/EVA/EVA5/capstone/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using CUDA device0 _CudaDeviceProperties(name='Tesla T4', total_memory=15079MB)\n",
            "\n",
            "use_pretrained True\n",
            "path midas/model-f6b98070.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_WSL-Images_master\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Summary: 1056 layers, 2.37595e+08 parameters, 2.37484e+08 gradients\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Caching labels (3160 found, 4 missing, 38 empty, 0 duplicate, for 3202 images): 100%|██████████| 3202/3202 [00:02<00:00, 1486.10it/s]\n",
            "Caching images (1.8GB): 100%|██████████| 3202/3202 [00:22<00:00, 143.34it/s]\n",
            "Caching labels (311 found, 0 missing, 7 empty, 0 duplicate, for 318 images): 100%|██████████| 318/318 [00:00<00:00, 2342.20it/s]\n",
            "Caching images (0.1GB): 100%|██████████| 318/318 [00:03<00:00, 103.16it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Image sizes 512 - 512 train, 512 test\n",
            "Using 0 dataloader workers\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "     Epoch   Dp_loss  bbx_loss  pln_loss  All_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     26/35      5.27      4.51      1.09      10.9       512: : 3202it [57:50,  1.08s/it]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "     Epoch   Dp_loss  bbx_loss  pln_loss  All_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     27/35      5.72      2.71      1.06      9.49       512: : 3202it [57:33,  1.08s/it]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "     Epoch   Dp_loss  bbx_loss  pln_loss  All_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     28/35      5.22      3.34      1.06      9.62       512: : 3202it [57:43,  1.08s/it]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "     Epoch   Dp_loss  bbx_loss  pln_loss  All_loss  img_size\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "     29/35      5.34      1.54      1.08      7.96       512: : 638it [11:38,  1.07s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6a2143acb23e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplane_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myolo_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmidas_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_plane_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_yolo_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_midas_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresume_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/EVA/EVA5/capstone/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Project_Vision/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(plane_args, yolo_args, midas_args, add_plane_loss, add_yolo_loss, add_midas_loss, resume_train, model_path)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;31m#if ni % accumulate == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m#torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uddmVqa29tGN"
      },
      "source": [
        "%debug"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4weo2gsyzS5_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqvNJDMrqdCj"
      },
      "source": [
        "#from torchsummary import summary\n",
        "\n",
        "#summary(model2, (3, 256, 256))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}